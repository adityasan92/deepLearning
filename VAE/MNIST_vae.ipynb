{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data in a format suited for tensorflow.\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "n_samples = mnist.train.num_examples\n",
    "print n_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 500\n",
    "n_z = 20\n",
    "batchsize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# leaky reLu unit\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)\n",
    "\n",
    "# standard convolution layer\n",
    "def conv2d(x, inputFeatures, outputFeatures, name):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable(\"w\",[5,5,inputFeatures, outputFeatures], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable(\"b\",[outputFeatures], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.conv2d(x, w, strides=[1,2,2,1], padding=\"SAME\") + b\n",
    "        return conv\n",
    "    \n",
    "# fully-conected layer\n",
    "def dense(x, inputFeatures, outputFeatures, scope=None, with_w=False):\n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        matrix = tf.get_variable(\"Matrix\", [inputFeatures, outputFeatures], tf.float32, tf.random_normal_initializer(stddev=0.02))\n",
    "        bias = tf.get_variable(\"bias\", [outputFeatures], initializer=tf.constant_initializer(0.0))\n",
    "        if with_w:\n",
    "            return tf.matmul(x, matrix) + bias, matrix, bias\n",
    "        else:\n",
    "            return tf.matmul(x, matrix) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "def recognition(input_images):\n",
    "    with tf.variable_scope(\"recognition\"):\n",
    "        h1 = lrelu(conv2d(input_images, 1, 16, \"d_h1\")) # 28x28x1 -> 14x14x16\n",
    "        h2 = lrelu(conv2d(h1, 16, 32, \"d_h2\")) # 14x14x16 -> 7x7x32\n",
    "        h2_flat = tf.reshape(h2,[ batchsize, 7*7*32])\n",
    "\n",
    "        w_mean = dense(h2_flat, 7*7*32, n_z, \"w_mean\")\n",
    "        w_stddev = dense(h2_flat, 7*7*32, n_z, \"w_stddev\")\n",
    "\n",
    "    return w_mean, w_stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(tf.float32, [None, 784])\n",
    "image_matrix = tf.reshape(images,[-1, 28, 28, 1])\n",
    "z_mean, z_stddev = recognition(image_matrix)\n",
    "samples = tf.random_normal([batchsize,n_z],0,1,dtype=tf.float32)\n",
    "guessed_z = z_mean + (z_stddev * samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_transpose(x, outputShape, name):\n",
    "    with tf.variable_scope(name):\n",
    "        # h, w, out, in\n",
    "        w = tf.get_variable(\"w\",[5,5, outputShape[-1], x.get_shape()[-1]], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable(\"b\",[outputShape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        convt = tf.nn.conv2d_transpose(x, w, output_shape=outputShape, strides=[1,2,2,1])\n",
    "        return convt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generation(z):\n",
    "        with tf.variable_scope(\"generation\"):\n",
    "            z_develop = dense(z, n_z, 7*7*32, scope='z_matrix')\n",
    "            z_matrix = tf.nn.relu(tf.reshape(z_develop, [batchsize, 7, 7, 32]))\n",
    "            h1 = tf.nn.relu(conv_transpose(z_matrix, [batchsize, 14, 14, 16], \"g_h1\"))\n",
    "            h2 = conv_transpose(h1, [batchsize, 28, 28, 1], \"g_h2\")\n",
    "            h2 = tf.nn.sigmoid(h2)\n",
    "\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_images = generation(guessed_z)\n",
    "generated_flat = tf.reshape(generated_images, [batchsize, 28*28])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generation_loss = -tf.reduce_sum(images * tf.log(1e-8 + generated_flat) + (1-images) * tf.log(1e-8 + 1 - generated_flat),1)\n",
    "latent_loss = 0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - 1,1)\n",
    "cost = tf.reduce_mean(generation_loss + latent_loss)\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge images \n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx / size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: genloss 543.428223 latloss 103.695709\n",
      "epoch 1: genloss 117.086739 latloss 18.449343\n",
      "epoch 2: genloss 89.644196 latloss 25.060406\n",
      "epoch 3: genloss 84.262054 latloss 24.091606\n",
      "epoch 4: genloss 85.664337 latloss 25.595249\n",
      "epoch 5: genloss 83.845215 latloss 26.101934\n",
      "epoch 6: genloss 80.723816 latloss 25.803059\n",
      "epoch 7: genloss 81.132957 latloss 25.296717\n",
      "epoch 8: genloss 75.649284 latloss 24.615320\n",
      "epoch 9: genloss 79.165138 latloss 26.536644\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "from scipy.misc import imsave as ims\n",
    "import os\n",
    "\n",
    "visualization = mnist.train.next_batch(batchsize)[0]\n",
    "reshaped_vis = visualization.reshape(batchsize,28,28)\n",
    "ims(\"base.jpg\",merge(reshaped_vis[:64],[8,8]))\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for epoch in range(10):\n",
    "        for idx in range(int(n_samples / batchsize)):\n",
    "            batch = mnist.train.next_batch(batchsize)[0]\n",
    "            _, gen_loss, lat_loss = sess.run((optimizer, generation_loss, latent_loss), feed_dict={images: batch})\n",
    "            # dumb hack to print cost every epoch\n",
    "            if idx % (n_samples - 3) == 0:\n",
    "                print \"epoch %d: genloss %f latloss %f\" % (epoch, np.mean(gen_loss), np.mean(lat_loss))\n",
    "                saver.save(sess, os.getcwd()+\"/train\",global_step=epoch)\n",
    "                generated_test = sess.run(generated_images, feed_dict={images: visualization})\n",
    "                generated_test = generated_test.reshape(batchsize,28,28)\n",
    "                ims(\"\"+str(epoch)+\".jpg\",merge(generated_test[:64],[8,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
